{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rbg-research/AI-Training/blob/main/voice-analytics/speech-analytics-deep-learning/session-1/Tutorial-1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems.\n",
    "* TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences.\n",
    "* The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.14.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (1.1.4)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (1.19.4)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.19 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (0.0.19)\n",
      "Requirement already satisfied: dill in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from datasets) (2021.7.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (5.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2020.11.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->datasets) (3.0.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas->datasets) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas->datasets) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Datasets is a library for easily accessing and sharing datasets, and evaluation metrics for Natural Language Processing (NLP), computer vision, and audio tasks.\n",
    "* For more details refer these [link1](https://huggingface.co/docs/datasets/index.html) and [link2](https://huggingface.co/datasets/viewer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset timit_asr/clean (download: 828.75 MiB, generated: 7.90 MiB, post-processed: Unknown size, total: 836.65 MiB) to /Users/hbbg/.cache/huggingface/datasets/timit_asr/clean/2.0.1/5bebea6cd9df0fc2c8c871250de23293a94c1dc49324182b330b6759ae6718f8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ef3c798cfb4b059b63d223b07f76cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/869M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "   'timit_asr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"load_dataset\" will download the corpus or will load the corpus if it is already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, train_labels = dataset[\"train\"][\"file\"], dataset[\"train\"][\"speaker_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files, test_labels = dataset[\"test\"][\"file\"], dataset[\"test\"][\"speaker_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Features, Visualiztion & Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "* For more details refer this [link](https://matplotlib.org/stable/tutorials/index.html)\n",
    "* librosa is a python package for music and audio analysis.\n",
    "* For more details refer this [link](https://librosa.org/doc/latest/tutorial.html)\n",
    "* Sklearn mostly used for performing feature preprocessing and conventional machine learning\n",
    "* For more details refer this [link](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_file = train_files[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , sr = librosa.load(demo_file)\n",
    "print(type(x), type(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load an audio file with specific sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , sr = librosa.load(demo_file, sr=16000)\n",
    "print(type(x), type(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting the audio duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.get_duration(y=x, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playing audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Waveform](https://en.wikipedia.org/wiki/Waveform) - loudness of the audio at a given time (time domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Spectogram](https://en.wikipedia.org/wiki/Spectrogram) - frequencies playing at a particular time along with it’s amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x) # converts data into short term Fourier transform\n",
    "# (amplitude of various frequencies playing at a given time of an audio signal)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz') \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x) # converts data into short term Fourier transform\n",
    "# (amplitude of various frequencies playing at a given time of an audio signal)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log') #log of frequencies  \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Zero Crossing Rate](https://en.wikipedia.org/wiki/Zero-crossing_rate) - rate of sign-changes along a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 0\n",
    "n1 = 10\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(x[n0:n1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)\n",
    "print(sum(zero_crossings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Spectral Centroid](https://en.wikipedia.org/wiki/Spectral_centroid) - weighted mean of the frequencies present in the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n",
    "spectral_centroids.shape\n",
    "\n",
    "frames = range(len(spectral_centroids))\n",
    "t = librosa.frames_to_time(frames) # computing the time variable for visualization\n",
    "\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis) # normalising the spectral centroid for visualisation\n",
    "\n",
    "librosa.display.waveplot(x, sr=sr, alpha=0.4) #plotting the Spectral Centroid along the waveform\n",
    "plt.plot(t, normalize(spectral_centroids), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Spectral Rolloff](https://github.com/erwanrh/ML_Python-Music_Classification/wiki/Spectral-roll-off) - frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_rolloff = librosa.feature.spectral_rolloff(x, sr=sr)[0]\n",
    "librosa.display.waveplot(x, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_rolloff), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [MFCC](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum) — Mel-Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs are commonly derived as follows:\n",
    "\n",
    "* Take the Fourier transform of (a windowed excerpt of) a signal.\n",
    "* Map the powers of the spectrum obtained above onto the mel scale, using triangular overlapping windows or alternatively, cosine overlapping windows.\n",
    "* Take the logs of the powers at each of the mel frequencies.\n",
    "* Take the discrete cosine transform of the list of mel log powers, as if it were a signal.\n",
    "* The MFCCs are the amplitudes of the resulting spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(x, sr=sr)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(x, sr=sr, n_mfcc=13)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Chromagram](https://en.wikipedia.org/wiki/Chroma_feature) - relates to the twelve different pitch classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = librosa.feature.chroma_stft(x, sr=sr)\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(chromagram, y_axis='chroma', x_axis='time')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
